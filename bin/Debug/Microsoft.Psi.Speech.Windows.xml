<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.Psi.Speech.Windows</name>
    </assembly>
    <members>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechRecognizer">
             <summary>
             Component that performs speech recognition using the desktop speech recognition engine from `System.Speech`.
             </summary>
             <remarks>
             This component performs continuous recognition on an audio stream. Recognition results are of type
             <see cref="T:Microsoft.Psi.Speech.StreamingSpeechRecognitionResult"/> which implements the <see cref="T:Microsoft.Psi.Speech.IStreamingSpeechRecognitionResult"/> interface.
             This pattern allows for results from speech recognition components based on different underlying technologies to conform to a
             common interface for consumption by downstream components. Messages on the Out stream contain final results, while messages on
             the PartialRecognitionResults stream contain partial results. Partial results contain partial hypotheses while speech is in
             progress and are useful for displaying hypothesized text as feedback to the user. The final result is emitted once the recognizer
             has determined that speech has ended, and will contain the top hypothesis for the utterance.
            
             The originating times of speech recognition events emitted by this component are estimates. These are estimated in a couple of ways
             from the results that the underlying speech recognition engine returns. In the case of a final recognition result, we use the audio
             position offset of the recognized audio as reported by the recognition engine to compute an estimate of the originating time. For
             partial hypotheses, we use the engine's current offset into the audio stream to estimate the originating time.
             </remarks>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechRecognizer.speechRecognitionEngine">
            <summary>
            The System.Speech speech recognition engine.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechRecognizer.inputAudioStream">
            <summary>
            Stream for buffering audio samples to send to the speech recognition engine.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechRecognizer.streamStartTime">
            <summary>
            The implied stream start time.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechRecognizer.lastPostedOriginatingTimes">
            <summary>
            The last originating time that was recorded for each output stream.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechRecognizer.recognizeComplete">
            <summary>
            Event to signal that the recognizer has been stopped.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechRecognizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configurationFilename">The component configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.ReceiveGrammars">
            <summary>
            Gets the receiver for new grammars.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.PartialRecognitionResults">
            <summary>
            Gets the output stream of partial recognition results.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.IntentData">
            <summary>
            Gets the output stream of intents and entities.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.SpeechDetected">
            <summary>
            Gets the output stream of speech detected events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.SpeechHypothesized">
            <summary>
            Gets the output stream of speech hypothesized events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.SpeechRecognized">
            <summary>
            Gets the output stream of speech recognized events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.SpeechRecognitionRejected">
            <summary>
            Gets the output stream of speech recognition rejected events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.AudioSignalProblemOccurred">
            <summary>
            Gets the output stream of audio problem events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.AudioStateChanged">
            <summary>
            Gets the output stream of audio state change events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.RecognizeCompleted">
            <summary>
            Gets the output stream of recognize completed events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.AudioLevelUpdated">
            <summary>
            Gets the output stream of audio level updated events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.EmulateRecognizeCompleted">
            <summary>
            Gets the output stream of emulate recognize completed completed events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.LoadGrammarCompleted">
            <summary>
            Gets the output stream of load grammar completed events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.RecognizerUpdateReached">
            <summary>
            Gets the output stream of recognizer update reached events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizer.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnPipelineStart">
            <summary>
            Called once all the subscriptions are established.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.SetGrammars(Microsoft.Psi.Message{System.Collections.Generic.IEnumerable{System.String}})">
            <summary>
            Replace grammars with given.
            </summary>
            <param name="srgsXmlGrammars">A collection of XML-format speech grammars that conform to the SRGS 1.0 specification.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.Dispose">
            <summary>
            Dispose method.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.Receive(Microsoft.Psi.Audio.AudioBuffer,Microsoft.Psi.Envelope)">
            <summary>
            Receiver for audio data.
            </summary>
            <param name="audio">A buffer containing the next chunk of audio data.</param>
            <param name="e">The message envelope for the audio data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.CreateSpeechRecognitionEngine">
            <summary>
            Creates a new speech recognition engine
            </summary>
            <returns>A new speech recognition engine object.</returns>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnRecognizeCompleted(System.Object,System.Speech.Recognition.RecognizeCompletedEventArgs)">
            <summary>
            Called when the engine finalizes the recognition operation.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnSpeechRecognized(System.Object,System.Speech.Recognition.SpeechRecognizedEventArgs)">
            <summary>
            Called when the final recognition result received.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnSpeechHypothesized(System.Object,System.Speech.Recognition.SpeechHypothesizedEventArgs)">
            <summary>
            Called whenever a partial recognition result is available.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnSpeechDetected(System.Object,System.Speech.Recognition.SpeechDetectedEventArgs)">
            <summary>
            Called when speech is detected.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnSpeechRecognitionRejected(System.Object,System.Speech.Recognition.SpeechRecognitionRejectedEventArgs)">
            <summary>
            Called when the engine is unable to match speech input to any of its enabled grammars.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.OnRecognizerUpdateReached(System.Object,System.Speech.Recognition.RecognizerUpdateReachedEventArgs)">
            <summary>
            Requested by `SetGrammars()` - now ready to update
            </summary>
            <param name="sender">Event sender</param>
            <param name="e">Event args (`UserToken` expected to contain grammars)</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.PostWithOriginatingTimeConsistencyCheck``1(Microsoft.Psi.Emitter{``0},``0,System.DateTime)">
            <summary>
            Posts a message to a stream while ensuring the consistency of the supplied originating time
            such that it cannot be before the originating time of the last posted message on the stream.
            If so, it will be adjusted accordingly.
            </summary>
            <remarks>
            Use this method when posting messages to output streams where the computed originating times of
            the messages are not guaranteed to be monotonically increasing, which is a requirement of Psi.
            </remarks>
            <typeparam name="T">The type of the output stream.</typeparam>
            <param name="stream">The stream on which to post.</param>
            <param name="data">The data to post.</param>
            <param name="originatingTime">The originating time of the data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.BuildSpeechRecognitionResult(System.Speech.Recognition.RecognitionResult)">
            <summary>
            Builds a SpeechRecognitionResult object from a RecognitionResult returned by the recognizer.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <returns>A SpeechRecognitionResult object containing the recognition results.</returns>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.BuildPartialSpeechRecognitionResult(System.Speech.Recognition.RecognitionResult)">
            <summary>
            Builds a SpeechRecognitionResult object from a partial RecognitionResult returned by the recognizer.
            </summary>
            <param name="result">The RecognitionResult object.</param>
            <returns>A SpeechRecognitionResult object containing the partial recognition result.</returns>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.BuildIntentData(System.Speech.Recognition.SemanticValue)">
            <summary>
            Method to construct the IntentData (intents and entities) from
            a SemanticValue.
            </summary>
            <param name="semanticValue">The SemanticValue object.</param>
            <returns>An IntentData object containing the intents and entities.</returns>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizer.ExtractEntities(System.Speech.Recognition.SemanticValue)">
            <summary>
            Method to extract all entities contained within a SemanticValue.
            </summary>
            <param name="semanticValue">The SemanticValue object.</param>
            <returns>The list of extracted entities.</returns>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration">
            <summary>
            Represents the configuration for the <see cref="T:Microsoft.Psi.Speech.SystemSpeechRecognizer"/> component.
            </summary>
            <remarks>
            Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechRecognizer"/> component.
            Refer to the properties in this class for more information on the various configuration options.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration.Language">
            <summary>
            Gets or sets the speech recognition language.
            </summary>
            <remarks>
            Use this to set the locale for speech recognition. If not specified, this defaults to "en-us"
            (U.S. English). Other supported locales include "en-gb", "de-de", "es-es", "fr-fr", "ja-jp",
            "zh-cn" and "zh-tw".
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration.Grammars">
            <summary>
            Gets or sets the list of grammar files.
            </summary>
            <remarks>
            Use this to specify a set of grammar files that the recognizer should use for speech recognition.
            Grammar files are XML-format files that conform to the
            <a href="http://go.microsoft.com/fwlink/?LinkId=201761">W3C Speech Recognition Grammar Specification (SRGS) Version 1.0</a>.
            If this configuration property is not specified or set to null, the recognizer will use a default
            context-free grammar used for free text dictation.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration.BufferLengthInMs">
            <summary>
            Gets or sets the length of the recognizer's input stream buffer in milliseconds.
            </summary>
            <remarks>
            Audio arriving on the input stream will be stored in an internal buffer for the speech recognition
            engine to read as it is able. This buffer will block when full until the recognition engine is able
            to read from the buffer. Set this value to modify the length of the buffer, which is computed based
            on the length of audio to buffer in milliseconds and the audio input format. By default, a 1000 ms
            buffer is used. It is safe to leave this value unchanged.
            </remarks>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechRecognizerConfiguration.InputFormat">
            <summary>
            Gets or sets the expected input format of the audio stream.
            </summary>
            <remarks>
            Preferred input audio formats are 1-channel, 16-bit PCM samples. Use the
            <see cref="M:Microsoft.Psi.Audio.WaveFormat.Create16kHz1Channel16BitPcm"/> or
            <see cref="M:Microsoft.Psi.Audio.WaveFormat.Create16BitPcm(System.Int32,System.Int32)"/> static methods to create the appropriate
            <see cref="T:Microsoft.Psi.Audio.WaveFormat"/> object. If not specified, a default value of 16000 Hz is assumed.
            </remarks>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer">
            <summary>
            Component that performs speech synthesis via the desktop speech synthesis engine from `System.Speech`.
            </summary>
            <remarks>
            This component performs text-to-speech synthesis, operating on an input stream of text strings and producing a
            stream of audio containing the synthesized speech.
            </remarks>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechSynthesizer.configuration">
            <summary>
            The configuration for this component.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechSynthesizer.speechSynthesizer">
            <summary>
            The System.Speech speech synthesizer.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemSpeechSynthesizer.pipeline">
            <summary>
            A pointer to the pipeline
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configurationFilename">The component configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.BookmarkReached">
            <summary>
            Gets the output stream of bookmark reached events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReached">
            <summary>
            Gets the output stream of phoneme reached events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakCompleted">
            <summary>
            Gets the output stream of speak completed
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgress">
            <summary>
            Gets the output stream of speak progress events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakStarted">
            <summary>
            Gets the output stream of speak started events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.StateChanged">
            <summary>
            Gets the output stream of state changed events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReached">
            <summary>
            Gets the output stream of viseme reached events
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.Write(System.String,Microsoft.Psi.Data.Exporter)">
            <summary>
            Writes all output stream to a store, with a given prefix
            </summary>
            <param name="prefix">The prefix for the streams.</param>
            <param name="store">The store to write the streams to</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.Dispose">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.Receive(System.String,Microsoft.Psi.Envelope)">
            <summary>
            Receiver for audio data.
            </summary>
            <param name="utteranceText">A string containing the next utterance to synthesize.</param>
            <param name="e">The message envelope for the next utterance to synthesize.</param>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.BookmarkReachedEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.BookmarkReachedEventData.#ctor(System.Speech.Synthesis.BookmarkReachedEventArgs)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.BookmarkReachedEventData"/> class.
            </summary>
            <param name="e">
            The event args from the System.Speech.Synthesis.SpeechSynthesizer.BookmarkReached event.
            </param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.BookmarkReachedEventData.Bookmark">
            <summary>
            Gets the name of the bookmark that was reached.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.BookmarkReachedEventData.AudioPosition">
            <summary>
            Gets the time offset at which the bookmark was reached.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData.#ctor(System.Speech.Synthesis.PhonemeReachedEventArgs)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData"/> class.
            </summary>
            <param name="e">
            The event args from the System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached event.
            </param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData.Phoneme">
            <summary>
            Gets the phoneme associated with the System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached event.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData.AudioPosition">
            <summary>
            Gets the audio position of the phoneme.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData.Duration">
            <summary>
            Gets the duration of the phoneme.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData.Emphasis">
            <summary>
            Gets the emphasis of the phoneme.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.PhonemeReachedEventData.NextPhoneme">
            <summary>
            Gets the phoneme following the phoneme associated with the
            System.Speech.Synthesis.SpeechSynthesizer.PhonemeReached event.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakCompletedEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.SpeakCompleted event.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData.#ctor(System.Speech.Synthesis.SpeakProgressEventArgs)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData"/> class.
            </summary>
            <param name="e">
            The event args from the System.Speech.Synthesis.SpeechSynthesizer.SpeakProgress event.
            </param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData.AudioPosition">
            <summary>
            Gets the audio position of the event.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData.CharacterPosition">
            <summary>
            Gets the number of characters and spaces from the beginning of the prompt to
            the position before the first letter of the word that was just spoken.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData.CharacterCount">
            <summary>
            Gets the number of characters in the word that was spoken just before the event
            was raised.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakProgressEventData.Text">
            <summary>
            Gets the text that was just spoken when the event was raised.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.SpeakStartedEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.SpeakStarted event.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.StateChangedEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.StateChanged event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.StateChangedEventData.#ctor(System.Speech.Synthesis.StateChangedEventArgs)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.StateChangedEventData"/> class.
            </summary>
            <param name="e">
            The event args from the System.Speech.Synthesis.SpeechSynthesizer.StateChanged event.
            </param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.StateChangedEventData.State">
            <summary>
            Gets the state of the System.Speech.Synthesis.SpeechSynthesizer after the
            System.Speech.Synthesis.SpeechSynthesizer.StateChanged event.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.StateChangedEventData.PreviousState">
            <summary>
            Gets the state of the System.Speech.Synthesis.SpeechSynthesizer before the
            System.Speech.Synthesis.SpeechSynthesizer.StateChanged event.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData">
            <summary>
            Represents data from the System.Speech.Synthesis.SpeechSynthesizer.VisemeReached event.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData.#ctor(System.Speech.Synthesis.VisemeReachedEventArgs)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData"/> class.
            </summary>
            <param name="e">
            The event args from the System.Speech.Synthesis.SpeechSynthesizer.VisemeReached event.
            </param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData.Viseme">
            <summary>
            Gets the value of the viseme.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData.AudioPosition">
            <summary>
            Gets the position of the viseme in the audio stream.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData.Duration">
            <summary>
            Gets the duration of the viseme.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData.Emphasis">
            <summary>
            Gets a System.Speech.Synthesis.SynthesizerEmphasis object that describes the
            emphasis of the viseme.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizer.VisemeReachedEventData.NextViseme">
            <summary>
            Gets the value of the next viseme.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer.IOStream">
            <summary>
            A System.IO.Stream adapter that takes a write delegate.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration">
            <summary>
            Represents the configuration for the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer"/> component.
            </summary>
            <remarks>
            Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizer"/> component.
            Refer to the properties in this class for more information on the various configuration options.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.Voice">
            <summary>
            Gets or sets the text-to-speech voice to use.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.PersistAudio">
            <summary>
            Gets or sets a value indicating whether the output audio stream is persisted.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.UseDefaultAudioPlaybackDevice">
            <summary>
            Gets or sets a value indicating whether synthesized speech audio
            output should be redirected to the default audio device instead of
            the output stream. Useful for debugging purposes.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.BufferLengthInMs">
            <summary>
            Gets or sets the length of the synthesizer's output audio buffer in milliseconds.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.ProsodyRate">
            <summary>
            Gets or sets the prosody rate for the speech.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.ProsodyPitch">
            <summary>
            Gets or sets the prosody pitch for the speech. Possible values: x-low, low, medium, high, x-high, or default
            Todo: make this an enum
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.ProsodyVolume">
            <summary>
            Gets or sets the prosody volume for the speech. Possible values: silent, x-soft, soft, medium, loud, x-loud, or default
            Todo: make this an enum
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemSpeechSynthesizerConfiguration.OutputFormat">
            <summary>
            Gets or sets the output format of the audio stream.
            </summary>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemVoiceActivityDetector">
            <summary>
            Component that performs voice activity detection by using the desktop speech recognition engine from `System.Speech`.
            </summary>
            <remarks>
            This component monitors an input audio stream and outputs a boolean flag for each input message indicating
            whether or not voice activity was present in the corresponding <see cref="T:Microsoft.Psi.Audio.AudioBuffer"/>. It relies on the
            System.Speech.Recognition.SpeechRecognitionEngine in .NET and uses its AudioStateChanged event to estimate
            when speech activity begins and ends. It estimates the originating times of these events using the current
            audio position of the underlying speech recognition engine to obtain an estimate of the time the event occurred.
            These results may be further fine-tuned to potentially obtain better estimates with the VoiceActivityStartOffsetMs
            and VoiceActivityEndOffsetMs configuration parameters, which are added to the inferred times.
            </remarks>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.configuration">
            <summary>
            The configuration for this component.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.speechRecognitionEngine">
            <summary>
            The System.Speech speech recognition engine.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.inputAudioStream">
            <summary>
            Stream for buffering audio samples to send to the speech recognition engine.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.streamStartTime">
            <summary>
            The implied stream start time.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.lastSpeechDetectedState">
            <summary>
            The most recent speech detected state.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.lastSpeechDetectedTime">
            <summary>
            The most recent time speech was detected.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.lastSilenceDetectedTime">
            <summary>
            The most recent time end-of-speech was detected.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.recognizeComplete">
            <summary>
            Event to signal that the recognizer has been stopped.
            </summary>
        </member>
        <member name="F:Microsoft.Psi.Speech.SystemVoiceActivityDetector.messageOriginatingTimes">
            <summary>
            Queue of input message originating times;
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.#ctor(Microsoft.Psi.Pipeline,Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemVoiceActivityDetector"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configuration">The component configuration.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.#ctor(Microsoft.Psi.Pipeline,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemVoiceActivityDetector"/> class.
            </summary>
            <param name="pipeline">The pipeline to add the component to.</param>
            <param name="configurationFilename">The component configuration file.</param>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetector.Configuration">
            <summary>
            Gets the configuration for this component.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.Dispose">
            <summary>
            Disposes of managed resources.
            </summary>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.Receive(Microsoft.Psi.Audio.AudioBuffer,Microsoft.Psi.Envelope)">
            <summary>
            Receiver for audio data.
            </summary>
            <param name="audioBuffer">A buffer containing the next chunk of audio data.</param>
            <param name="e">The message envelope for the audio data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.CreateSpeechRecognitionEngine">
            <summary>
            Creates a new speech recognition engine
            </summary>
            <returns>A new speech recognition engine object.</returns>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.OnAudioStateChanged(System.Object,System.Speech.Recognition.AudioStateChangedEventArgs)">
            <summary>
            Called when the audio state of the recognizer changes.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetector.OnRecognizeCompleted(System.Object,System.Speech.Recognition.RecognizeCompletedEventArgs)">
            <summary>
            Called when the engine finalizes the recognition operation.
            </summary>
            <param name="sender">The source of the event.</param>
            <param name="e">An object that contains the event data.</param>
        </member>
        <member name="T:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration">
            <summary>
            Represents the configuration for the <see cref="T:Microsoft.Psi.Speech.SystemVoiceActivityDetector"/> component.
            </summary>
            <remarks>
            Use this class to configure a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemVoiceActivityDetector"/> component.
            Refer to the properties in this class for more information on the various configuration options.
            </remarks>
        </member>
        <member name="M:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.Language">
            <summary>
            Gets or sets the speech recognition language.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.Grammars">
            <summary>
            Gets or sets the list of grammar files.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.BufferLengthInMs">
            <summary>
            Gets or sets the length of the recognizer's input stream buffer in milliseconds.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.VoiceActivityStartOffsetMs">
            <summary>
            Gets or sets the offset in milliseconds to add to the detected start of speech.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.VoiceActivityEndOffsetMs">
            <summary>
            Gets or sets the offset in milliseconds to add to the detected end of speech.
            </summary>
        </member>
        <member name="P:Microsoft.Psi.Speech.SystemVoiceActivityDetectorConfiguration.InputFormat">
            <summary>
            Gets or sets the expected input format of the audio stream.
            </summary>
        </member>
    </members>
</doc>
